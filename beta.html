<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <title>Barcode Scanner Benchmark (Quagga / Quagga2 / ZXing)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root { color-scheme: light dark; }
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Noto Sans JP, sans-serif; margin: 16px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    .row { display: flex; gap: 12px; flex-wrap: wrap; align-items: center; margin-bottom: 8px; }
    label { display: inline-flex; align-items: center; gap: 6px; }
    select, button { font: inherit; padding: 6px 8px; }
    button { cursor: pointer; }
    #video { width: min(480px, 90vw); aspect-ratio: 3 / 2; background: #000; border-radius: 8px; display: block; }
    #overlay { position: relative; width: min(480px, 90vw); height: calc((min(480px, 90vw)) * 2 / 3); margin-top: 8px; }
    #log { margin-top: 8px; padding: 8px; border: 1px solid #8884; border-radius: 8px; white-space: pre-wrap; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace; min-height: 100px; }
    .note { font-size: 12px; color: #888; }
    .pill { padding: 2px 6px; border-radius: 999px; background: #8882; font-size: 11px; }
    .grid { display: grid; grid-template-columns: 1fr; gap: 12px; }
    @media (min-width: 980px) { .grid { grid-template-columns: 520px 1fr; align-items: start; } }
    .kbd { font-family: ui-monospace, monospace; background: #8882; padding: 1px 5px; border-radius: 4px; }
    .warn { color: #b35300; }
    .ok { color: #0a7a3c; }
    .err { color: #b00020; }
    canvas.debug { position:absolute; top:0; left:0; width:100%; height:100%; pointer-events:none; }
  </style>
</head>
<body>
  <h1>Barcode Scanner Benchmark</h1>
  <div class="row">
    <label>ライブラリ:
      <select id="lib">
        <option value="quagga">Quagga (serratus/quaggaJS)</option>
        <option value="quagga2">Quagga2 (@ericblade/quagga2)</option>
        <option value="zxing">ZXing (@zxing/library)</option>
      </select>
    </label>

    <label>カメラ:
      <select id="device"></select>
    </label>

    <label>解像度プリセット:
      <select id="preset">
        <option value="720p">1280x720</option>
        <option value="540p">960x540</option>
        <option value="480p">854x480</option>
        <option value="1080p">1920x1080</option>
      </select>
    </label>

    <span class="pill">EAN-13/ISBN 用に最適化</span>
  </div>

  <div class="row">
    <button id="btnInit">カメラ起動</button>
    <button id="btnStart">認識開始</button>
    <button id="btnStop">停止</button>
    <button id="btnTeardown">解放</button>
    <button id="btnExport">CSV出力</button>
  </div>

  <div class="note">
    計測: 起動時間（カメラ起動クリック→ライブラリ初期化完了）と、認識開始→最初のバーコード検出までの時間を記録します。<br />
    注: 教科書ISBNは多くが EAN-13（978/979 プレフィックス）です。ZXing は EAN-13 のみに絞って高速化しています。
  </div>

  <div class="grid">
    <div>
      <div id="overlay">
        <video id="video" playsinline muted></video>
        <!-- Quagga/Quagga2 の処理中に内部で生成される canvas が undefined の data を読みに行くことがあるため、
             明示的にデバッグキャンバスを配置し、描画先を固定する -->
        <canvas id="debugCanvas" class="debug"></canvas>
      </div>
      <div id="log"></div>
      <div class="note">
        トラブルシュート:
        <ul>
          <li>HTTPS で配信してください（カメラはセキュアコンテキストが必要）。</li>
          <li>iOS Safari ではユーザ操作後のみ再生可能。ボタンから開始してください。</li>
          <li>他タブや他アプリがカメラを使用中だと取得に失敗します。</li>
        </ul>
      </div>
    </div>
    <div>
      <h3 style="margin:8px 0">このページの目的と設計</h3>
      <p>
        1つのHTML内で Quagga / Quagga2 / ZXing を切替え、(1)カメラ初期化の起動時間 と (2)「認識開始」→最初の検出までの時間 を比較計測します。
        以前発生した <span class="kbd">TypeError: Ut[e] is not a constructor</span> と今回の
        <span class="kbd">TypeError: Cannot read properties of undefined (reading 'data')</span> を回避するため、ライブラリの衝突防止・初期化順序・
        Quaggaのデバッグ描画ハンドラを適正化しています。
      </p>
      <h4 style="margin:8px 0">今回のエラーの原因と対策</h4>
      <ul>
        <li>原因の多くは Quagga の <span class="kbd">onProcessed</span> デバッグ描画で <span class="kbd">res.boxes</span> 等が未定義のフレームに対して
            <span class="kbd">ctx.putImageData</span> 相当の処理が走ること、もしくは <span class="kbd">inputStream</span> の設定不整合で内部 canvas が未生成のままアクセスされること。</li>
        <li>対策:
          <ul>
            <li>onProcessed のガード強化（res と res.boxes 等を厳密チェック）。</li>
            <li>inputStream.target に実在する要素（video）を指定し、<b>クラス名</b>や <b>constaints</b> を正しく付与。</li>
            <li>デバッグ用 canvas を明示的に配置（debugCanvas）し、描画先を固定して undefined を回避。</li>
            <li>start 前に <span class="kbd">stop()</span> を呼び、ハンドラ多重と内部状態不整合を防止。</li>
          </ul>
        </li>
      </ul>
      <h4 style="margin:8px 0">ZXing 高速化の要点</h4>
      <ul>
        <li>DecodeHintType.POSSIBLE_FORMATS を EAN_13 のみに限定。</li>
        <li>解像度を 720p などに制限して総ピクセル数を抑制。</li>
        <li>最初のヒットで停止（連続処理を避ける）。</li>
      </ul>
    </div>
  </div>

  <!-- 固定バージョンで読み込みし、直後に退避して衝突回避 -->
  <!-- Quagga (serratus/quaggaJS) -->
  <script src="https://unpkg.com/quagga@0.12.1/dist/quagga.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script>
    window.__Quagga_v0121__ = window.Quagga;
  </script>

  <!-- Quagga2 (@ericblade/quagga2) -->
  <script src="https://unpkg.com/@ericblade/quagga2@1.7.2/dist/quagga.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script>
    window.__Quagga2_v172__ = window.Quagga;
    try { delete window.Quagga; } catch (e) { window.Quagga = undefined; }
  </script>

  <!-- ZXing (@zxing/library) -->
  <script src="https://unpkg.com/@zxing/library@0.20.0" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script>
    // ユーティリティ
    const $ = (s)=>document.querySelector(s);
    const video = $("#video");
    const debugCanvas = $("#debugCanvas");
    const selLib = $("#lib");
    const selDev = $("#device");
    const selPreset = $("#preset");
    const logView = $("#log");

    const log = (...a) => {
      const line = a.map(v => {
        if (v instanceof Error) return `${v.name}: ${v.message}`;
        if (typeof v === 'object') try { return JSON.stringify(v); } catch { return String(v); }
        return String(v);
      }).join(" ");
      logView.textContent += line + "\n";
      logView.scrollTop = logView.scrollHeight;
      console.log("[LOG]", ...a);
    };
    const warn = (...a)=>log("⚠️", ...a);
    const ok = (...a)=>log("✅", ...a);
    const err = (...a)=>log("❌", ...a);

    // 計測・結果保存
    let adapter = null;
    let stream = null;
    let t0=0, t1=0, s0=0, s1=0;
    const results = []; // { ts, lib, deviceLabel, preset, init_ms, detect_ms, text, format }

    function recordResult(meta) {
      results.push({ ts: new Date().toISOString(), ...meta });
    }

    function exportCSV() {
      if (!results.length) { warn("出力可能な結果がありません。少なくとも1回スキャンしてください。"); return; }
      const header = ["timestamp","library","device","preset","init_ms","detect_ms","text","format"];
      const rows = results.map(r => ([
        r.ts, r.lib, r.deviceLabel ?? "", r.preset ?? "",
        r.init_ms ?? "", r.detect_ms ?? "", r.text ?? "", r.format ?? ""
      ].map(v => {
        const s = (v == null) ? "" : String(v);
        return /[",\n]/.test(s) ? `"${s.replace(/"/g,'""')}"` : s;
      }).join(",")));
      const csv = [header.join(","), ...rows].join("\n");
      const blob = new Blob([csv], { type: "text/csv;charset=utf-8" });
      const url = URL.createObjectURL(blob);
      const a = document.createElement("a");
      a.href = url;
      a.download = `barcode_benchmark_${new Date().toISOString().replace(/[:.]/g,'-')}.csv`;
      a.click();
      URL.revokeObjectURL(url);
      ok("CSV をダウンロードしました。");
    }

    // デバイス列挙
    async function listDevices() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const vids = devices.filter(d=>d.kind === "videoinput");
      selDev.innerHTML = "";
      for (const d of vids) {
        const opt = document.createElement("option");
        opt.value = d.deviceId;
        opt.textContent = d.label || d.deviceId || "camera";
        selDev.appendChild(opt);
      }
      if (!vids.length) warn("カメラが見つかりません。権限や接続を確認してください。");
    }

    // 解像度プリセット → constraints 合成
    function getConstraints() {
      const deviceId = selDev.value || undefined;
      const preset = selPreset.value;
      const sizeMap = {
        "540p": { width: 960, height: 540 },
        "480p": { width: 854, height: 480 },
        "720p": { width: 1280, height: 720 },
        "1080p": { width: 1920, height: 1080 },
      };
      const wh = sizeMap[preset] || sizeMap["720p"];
      const baseVideo = deviceId ? { deviceId: { exact: deviceId } } : { facingMode: "environment" };
      const videoConstraint = Object.assign({}, baseVideo, {
        width: { ideal: wh.width },
        height: { ideal: wh.height },
        frameRate: { ideal: 30 }
      });
      return { audio: false, video: videoConstraint };
    }

    // Quagga の onProcessed 用デバッグ描画（undefined ガード付）
    function attachQuaggaDebugHandlers(Q, videoEl, canvasEl) {
      try {
        if (!Q || typeof Q.onProcessed !== "function") return;
        const ctx = canvasEl.getContext("2d");
        Q.onProcessed(function(result) {
          // 結果が無い・途中フレームの場合は何もしない
          if (!result || !ctx) return;
          // キャンバスのサイズを video に合わせる
          const rect = videoEl.getBoundingClientRect();
          const w = Math.max(1, Math.floor(rect.width));
          const h = Math.max(1, Math.floor(rect.height));
          if (canvasEl.width !== w) canvasEl.width = w;
          if (canvasEl.height !== h) canvasEl.height = h;
          ctx.clearRect(0, 0, w, h);

          // boxes（候補領域）があれば描画
          if (Array.isArray(result.boxes)) {
            ctx.strokeStyle = "rgba(0,255,0,0.6)";
            ctx.lineWidth = 2;
            result.boxes.forEach(box => {
              if (!Array.isArray(box)) return;
              ctx.beginPath();
              box.forEach((p, i) => {
                if (!p || typeof p.x !== "number" || typeof p.y !== "number") return;
                if (i === 0) ctx.moveTo(p.x, p.y); else ctx.lineTo(p.x, p.y);
              });
              ctx.closePath();
              ctx.stroke();
            });
          }

          // line（バーコード中心ライン）があれば描画
          if (result.line && result.line && result.line[0] && result.line[1]) {
            const a = result.line[0], b = result.line[1];
            if (a && b && typeof a.x === "number" && typeof a.y === "number" && typeof b.x === "number" && typeof b.y === "number") {
              ctx.strokeStyle = "rgba(255,0,0,0.8)";
              ctx.lineWidth = 3;
              ctx.beginPath();
              ctx.moveTo(a.x, a.y);
              ctx.lineTo(b.x, b.y);
              ctx.stroke();
            }
          }
        });
      } catch (e) {
        // デバッグ描画が失敗しても本体処理には影響しないようにする
        warn("Quaggaデバッグ描画の設定で例外が発生しましたが無視します。", e);
      }
    }

    // アダプタ
    const Adapters = {
      quagga: {
        Q: window.__Quagga_v0121__,
        _detectedHandler: null,
        async init(videoEl, constraints) {
          t0 = performance.now();
          // 先にユーザメディアを確保してプレビューに載せる
          stream = await navigator.mediaDevices.getUserMedia(constraints);
          videoEl.srcObject = stream;
          await videoEl.play();

          await new Promise((res, rej) => {
            try {
              this.Q.init({
                inputStream: {
                  name: "Live",
                  type: "LiveStream",
                  // target は video 要素を指定
                  target: videoEl,
                  constraints: constraints.video
                },
                locator: { patchSize: "medium", halfSample: true }, // 安定化
                decoder: { readers: ["ean_reader"] }, // EAN のみに絞る
                locate: true,
                numOfWorkers: (typeof navigator !== "undefined" && navigator.hardwareConcurrency) ? Math.max(1, Math.min(4, navigator.hardwareConcurrency - 1)) : 2
              }, (err) => err ? rej(err) : res());
            } catch (e) { rej(e); }
          });

          // デバッグ描画（undefinedガード付き）
          attachQuaggaDebugHandlers(this.Q, videoEl, debugCanvas);

          t1 = performance.now();
        },
        async startScan(onResult) {
          // 多重開始防止：開始前に安全に stop
          try { this.Q.stop(); } catch {}
          // 過去のハンドラを明示的に解除（onDetected多重対策）
          if (this._detectedHandler && typeof this.Q.offDetected === "function") {
            try { this.Q.offDetected(this._detectedHandler); } catch {}
          }
          s0 = performance.now();

          this._detectedHandler = (res) => {
            if (!res || !res.codeResult || !res.codeResult.code) return;
            s1 = performance.now();
            onResult({ text: res.codeResult.code, format: res.codeResult.format });
            try { this.Q.stop(); } catch {}
          };

          // Quagga 0.12 系には offDetected がない場合があるので、あれば使用
          if (typeof this.Q.onDetected === "function") {
            this.Q.onDetected(this._detectedHandler);
          }

          // 認識開始
          this.Q.start();
        },
        async stopScan() {
          try { this.Q.stop(); } catch {}
        },
        async teardown() {
          try { this.Q.stop(); } catch {}
          if (typeof this.Q.offProcessed === "function") {
            try { this.Q.offProcessed(); } catch {}
          }
          if (typeof this.Q.offDetected === "function" && this._detectedHandler) {
            try { this.Q.offDetected(this._detectedHandler); } catch {}
          }
          this._detectedHandler = null;
          if (stream) {
            stream.getTracks().forEach(t => t.stop());
            stream = null;
          }
          video.srcObject = null;
          // デバッグキャンバスをクリア
          const ctx = debugCanvas.getContext("2d");
          if (ctx) ctx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
        }
      },
      quagga2: {
        Q2: window.__Quagga2_v172__,
        _detectedHandler: null,
        async init(videoEl, constraints) {
          t0 = performance.now();
          stream = await navigator.mediaDevices.getUserMedia(constraints);
          videoEl.srcObject = stream;
          await videoEl.play();

          await new Promise((res, rej) => {
            try {
              this.Q2.init({
                inputStream: {
                  name: "Live",
                  type: "LiveStream",
                  target: videoEl,
                  constraints: constraints.video
                },
                locator: { patchSize: "medium", halfSample: true },
                decoder: { readers: ["ean_reader"] },
                locate: true,
                numOfWorkers: (typeof navigator !== "undefined" && navigator.hardwareConcurrency) ? Math.max(1, Math.min(4, navigator.hardwareConcurrency - 1)) : 2
              }, (err) => err ? rej(err) : res());
            } catch (e) { rej(e); }
          });

          attachQuaggaDebugHandlers(this.Q2, videoEl, debugCanvas);

          t1 = performance.now();
        },
        async startScan(onResult) {
          // 安全策：開始前に停止
          try { this.Q2.stop(); } catch {}
          // ハンドラ多重解除
          if (this._detectedHandler && typeof this.Q2.offDetected === "function") {
            try { this.Q2.offDetected(this._detectedHandler); } catch {}
          }
          s0 = performance.now();

          this._detectedHandler = (res) => {
            if (!res || !res.codeResult || !res.codeResult.code) return;
            s1 = performance.now();
            onResult({ text: res.codeResult.code, format: res.codeResult.format });
            try { this.Q2.stop(); } catch {}
          };

          if (typeof this.Q2.onDetected === "function") {
            this.Q2.onDetected(this._detectedHandler);
          }

          this.Q2.start();
        },
        async stopScan() {
          try { this.Q2.stop(); } catch {}
        },
        async teardown() {
          try { this.Q2.stop(); } catch {}
          if (typeof this.Q2.offProcessed === "function") {
            try { this.Q2.offProcessed(); } catch {}
          }
          if (typeof this.Q2.offDetected === "function" && this._detectedHandler) {
            try { this.Q2.offDetected(this._detectedHandler); } catch {}
          }
          this._detectedHandler = null;
          if (stream) {
            stream.getTracks().forEach(t => t.stop());
            stream = null;
          }
          video.srcObject = null;
          const ctx = debugCanvas.getContext("2d");
          if (ctx) ctx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
        }
      },
      zxing: {
        _reader: null,
        _running: false,
        async init(videoEl, constraints) {
          t0 = performance.now();
          const tuned = JSON.parse(JSON.stringify(constraints));
          tuned.video = tuned.video || {};
          if (typeof tuned.video === "object") {
            if (!('width' in tuned.video)) tuned.video.width = { ideal: 1280 };
            if (!('height' in tuned.video)) tuned.video.height = { ideal: 720 };
            if (!('frameRate' in tuned.video)) tuned.video.frameRate = { ideal: 30 };
          }
          stream = await navigator.mediaDevices.getUserMedia(tuned);
          videoEl.srcObject = stream;
          await videoEl.play();

          // ZXing: EAN-13 限定
          const hints = new Map();
          hints.set(ZXing.DecodeHintType.POSSIBLE_FORMATS, [ZXing.BarcodeFormat.EAN_13]);
          // TRY_HARDER はデフォルト無効（必要なら下行を有効化）
          // hints.set(ZXing.DecodeHintType.TRY_HARDER, true);

          this._reader = new ZXing.BrowserMultiFormatReader(hints);
          t1 = performance.now();
        },
        async startScan(onResult) {
          if (this._running) return;
          this._running = true;
          s0 = performance.now();
          this._reader.decodeFromVideoElementContinuously(video, (result, err) => {
            if (result) {
              const txt = result.getText();
              if (!s1) s1 = performance.now();
              onResult({ text: txt, format: result.getBarcodeFormat() });
              this._reader.reset();
              this._running = false;
            }
          });
        },
        async stopScan() {
          if (this._reader) this._reader.reset();
          this._running = false;
        },
        async teardown() {
          await this.stopScan();
          if (stream) {
            stream.getTracks().forEach(t => t.stop());
            stream = null;
          }
          video.srcObject = null;
          this._reader = null;
          const ctx = debugCanvas.getContext("2d");
          if (ctx) ctx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
        }
      }
    };

    async function ensureAdapter() {
      const key = selLib.value;
      return Adapters[key];
    }

    function printTimes() {
      if (t0 && t1) log(`起動時間: ${(t1 - t0).toFixed(1)} ms`);
      if (s0 && s1) log(`認識開始→検出: ${(s1 - s0).toFixed(1)} ms`);
    }

    // イベント
    $("#btnInit").onclick = async () => {
      try {
        if (adapter) await adapter.teardown();
        // デバッグキャンバス初期化（サイズは video の描画時に合わせる）
        const ctx = debugCanvas.getContext("2d");
        if (ctx) ctx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);

        adapter = await ensureAdapter();
        const constraints = getConstraints();
        t0 = 0; t1 = 0; s0 = 0; s1 = 0;
        await adapter.init(video, constraints);
        const devLabel = selDev.selectedOptions[0]?.textContent || "";
        const preset = selPreset.value;
        ok(`[${selLib.value}] カメラ起動完了  device="${devLabel}" preset=${preset}`);
        printTimes();

        recordResult({
          lib: selLib.value,
          deviceLabel: devLabel,
          preset,
          init_ms: (t1 && t0) ? (t1 - t0).toFixed(1) : "",
          detect_ms: "",
          text: "",
          format: ""
        });
      } catch (e) {
        err("init error:", e);
      }
    };

    $("#btnStart").onclick = async () => {
      try {
        if (!adapter) { warn("先に「カメラ起動」を実行してください。"); return; }
        s0 = 0; s1 = 0;
        const devLabel = selDev.selectedOptions[0]?.textContent || "";
        const preset = selPreset.value;
        await adapter.startScan((res) => {
          ok(`検出: ${res.text} (${res.format})`);
          printTimes();
          recordResult({
            lib: selLib.value,
            deviceLabel: devLabel,
            preset,
            init_ms: (t1 && t0) ? (t1 - t0).toFixed(1) : "",
            detect_ms: (s1 && s0) ? (s1 - s0).toFixed(1) : "",
            text: res.text,
            format: res.format
          });
        });
      } catch (e) {
        err("start error:", e);
      }
    };

    $("#btnStop").onclick = async () => {
      try {
        await adapter?.stopScan();
        ok("停止しました。");
      } catch (e) {
        err("stop error:", e);
      }
    };

    $("#btnTeardown").onclick = async () => {
      try {
        await adapter?.teardown();
        adapter = null;
        ok("解放しました。");
      } catch (e) {
        err("teardown error:", e);
      }
    };

    $("#btnExport").onclick = exportCSV;

    // 初期セットアップ: カメラ一覧（ラベル取得のため初回のみ一時的に権限付与を試みる）
    (async () => {
      try {
        const tmp = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
        tmp.getTracks().forEach(t => t.stop());
      } catch (e) {
        warn("カメラ権限の事前取得に失敗しました（後続で再試行します）。", e);
      }
      try {
        await listDevices();
        ok("カメラ一覧を取得しました。");
      } catch (e) {
        err("カメラ一覧の取得に失敗しました。", e);
      }
    })();

    // 備考:
    // - 今回の "Cannot read properties of undefined (reading 'data')" を防ぐため、
    //   Quagga/Quagga2 の onProcessed では result の存在と各プロパティの存在を厳密にチェック。
    // - inputStream.target は実在の video 要素に固定し、constraints も一致させて内部の描画ターゲットが undefined にならないようにしています。
    // - start 前に stop、ハンドラの明示的解除で状態不整合を防止。
  </script>
</body>
</html>
