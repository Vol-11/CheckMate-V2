<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <title>Barcode Scanner Benchmark (Quagga / Quagga2 / ZXing) - fixed</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root { color-scheme: light dark; }
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Noto Sans JP, sans-serif; margin: 16px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    .row { display: flex; gap: 12px; flex-wrap: wrap; align-items: center; margin-bottom: 8px; }
    label { display: inline-flex; align-items: center; gap: 6px; }
    select, button { font: inherit; padding: 6px 8px; }
    button { cursor: pointer; }
    #stage { position: relative; width: min(480px, 90vw); }
    #video { width: 100%; aspect-ratio: 3 / 2; background: #000; border-radius: 8px; display: block; }
    #quaggaOverlay { position: absolute; inset: 0; pointer-events: none; }
    #log { margin-top: 8px; padding: 8px; border: 1px solid #8884; border-radius: 8px; white-space: pre-wrap; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace; min-height: 100px; }
    .note { font-size: 12px; color: #888; }
    .pill { padding: 2px 6px; border-radius: 999px; background: #8882; font-size: 11px; }
    .grid { display: grid; grid-template-columns: 1fr; gap: 12px; }
    @media (min-width: 980px) { .grid { grid-template-columns: 520px 1fr; align-items: start; } }
    .kbd { font-family: ui-monospace, monospace; background: #8882; padding: 1px 5px; border-radius: 4px; }
    .warn { color: #b35300; }
    .ok { color: #0a7a3c; }
    .err { color: #b00020; }
  </style>
</head>
<body>
  <h1>Barcode Scanner Benchmark</h1>

  <div class="row">
    <label>ライブラリ:
      <select id="lib">
        <option value="quagga">Quagga (serratus/quaggaJS)</option>
        <option value="quagga2">Quagga2 (@ericblade/quagga2)</option>
        <option value="zxing">ZXing (@zxing/library)</option>
      </select>
    </label>

    <label>カメラ:
      <select id="device"></select>
    </label>

    <label>解像度プリセット:
      <select id="preset">
        <option value="720p">1280x720</option>
        <option value="540p">960x540</option>
        <option value="480p">854x480</option>
        <option value="1080p">1920x1080</option>
      </select>
    </label>

    <span class="pill">EAN-13/ISBN 用に最適化</span>
  </div>

  <div class="row">
    <button id="btnInit">カメラ起動</button>
    <button id="btnStart">認識開始</button>
    <button id="btnStop">停止</button>
    <button id="btnTeardown">解放</button>
    <button id="btnExport">CSV出力</button>
  </div>

  <div class="note">
    計測: 起動時間（カメラ起動クリック→ライブラリ初期化完了）と、認識開始→最初のバーコード検出までの時間を記録します。<br />
    注: 教科書ISBNは多くが EAN-13（978/979 プレフィックス）です。ZXing は EAN-13 のみに絞って高速化しています。
  </div>

  <div class="grid">
    <div>
      <div id="stage">
        <video id="video" playsinline muted></video>
        <!-- 重要: Quagga が内部で生成する canvas に依存しないよう、明示の overlay を用意 -->
        <canvas id="quaggaOverlay"></canvas>
      </div>
      <div id="log"></div>
      <div class="note">
        トラブルシュート:
        <ul>
          <li>HTTPS で配信してください（カメラはセキュアコンテキストが必要）。</li>
          <li>iOS Safari ではユーザ操作後のみ再生可能。ボタンから開始してください。</li>
          <li>他タブや他アプリがカメラを使用中だと取得に失敗します。</li>
        </ul>
      </div>
    </div>
    <div>
      <h3 style="margin:8px 0">この修正の要点</h3>
      <ul>
        <li>エラー: TypeError: Cannot read properties of undefined (reading 'data') は Quagga 内部で未初期化の ImageData を参照するケースで発生することがある。</li>
        <li>対策:
          <ul>
            <li>inputStreamを Quagga が最も安定する Canvas ベースへ変更（type: "LiveStream" + willReadFrequently）。</li>
            <li>Patch: locator.halfSample: true、locate: true、numOfWorkers を妥当化。</li>
            <li>onProcessed の描画は完全ガード。内部の boxes/line が未定義でも落ちない。</li>
            <li>start 前に stop、検出ハンドラを一意にし、内部状態のねじれを防止。</li>
          </ul>
        </li>
        <li>ZXing は EAN_13 限定ヒントで高速化。解像度はプリセットから指定。</li>
      </ul>
    </div>
  </div>

  <!-- ライブラリ（バージョン固定＋退避で衝突回避） -->
  <script src="https://unpkg.com/quagga@0.12.1/dist/quagga.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script> window.__Quagga_v0121__ = window.Quagga; </script>

  <script src="https://unpkg.com/@ericblade/quagga2@1.7.2/dist/quagga.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script>
    window.__Quagga2_v172__ = window.Quagga;
    try { delete window.Quagga; } catch (e) { window.Quagga = undefined; }
  </script>

  <script src="https://unpkg.com/@zxing/library@0.20.0" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script>
    // ユーティリティ
    const $ = (s)=>document.querySelector(s);
    const video = $("#video");
    const overlay = $("#quaggaOverlay");
    const selLib = $("#lib");
    const selDev = $("#device");
    const selPreset = $("#preset");
    const logView = $("#log");

    const log = (...a) => {
      const line = a.map(v => {
        if (v instanceof Error) return `${v.name}: ${v.message}`;
        if (typeof v === 'object') try { return JSON.stringify(v); } catch { return String(v); }
        return String(v);
      }).join(" ");
      logView.textContent += line + "\n";
      logView.scrollTop = logView.scrollHeight;
      console.log("[LOG]", ...a);
    };
    const warn = (...a)=>log("⚠️", ...a);
    const ok = (...a)=>log("✅", ...a);
    const err = (...a)=>log("❌", ...a);

    // 計測・結果保存
    let adapter = null;
    let stream = null;
    let t0=0, t1=0, s0=0, s1=0;
    const results = []; // { ts, lib, deviceLabel, preset, init_ms, detect_ms, text, format }

    function recordResult(meta) {
      results.push({ ts: new Date().toISOString(), ...meta });
    }

    function exportCSV() {
      if (!results.length) { warn("出力可能な結果がありません。少なくとも1回スキャンしてください。"); return; }
      const header = ["timestamp","library","device","preset","init_ms","detect_ms","text","format"];
      const rows = results.map(r => ([
        r.ts, r.lib, r.deviceLabel ?? "", r.preset ?? "",
        r.init_ms ?? "", r.detect_ms ?? "", r.text ?? "", r.format ?? ""
      ].map(v => {
        const s = (v == null) ? "" : String(v);
        return /[",\n]/.test(s) ? `"${s.replace(/"/g,'""')}"` : s;
      }).join(",")));
      const csv = [header.join(","), ...rows].join("\n");
      const blob = new Blob([csv], { type: "text/csv;charset=utf-8" });
      const url = URL.createObjectURL(blob);
      const a = document.createElement("a");
      a.href = url;
      a.download = `barcode_benchmark_${new Date().toISOString().replace(/[:.]/g,'-')}.csv`;
      a.click();
      URL.revokeObjectURL(url);
      ok("CSV をダウンロードしました。");
    }

    // デバイス列挙
    async function listDevices() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const vids = devices.filter(d=>d.kind === "videoinput");
      selDev.innerHTML = "";
      for (const d of vids) {
        const opt = document.createElement("option");
        opt.value = d.deviceId;
        opt.textContent = d.label || d.deviceId || "camera";
        selDev.appendChild(opt);
      }
      if (!vids.length) warn("カメラが見つかりません。権限や接続を確認してください。");
    }

    // 解像度プリセット → constraints 合成
    function getConstraints() {
      const deviceId = selDev.value || undefined;
      const preset = selPreset.value;
      const sizeMap = {
        "540p": { width: 960, height: 540 },
        "480p": { width: 854, height: 480 },
        "720p": { width: 1280, height: 720 },
        "1080p": { width: 1920, height: 1080 },
      };
      const wh = sizeMap[preset] || sizeMap["720p"];
      const baseVideo = deviceId ? { deviceId: { exact: deviceId } } : { facingMode: "environment" };
      const videoConstraint = Object.assign({}, baseVideo, {
        width: { ideal: wh.width },
        height: { ideal: wh.height },
        frameRate: { ideal: 30 }
      });
      return { audio: false, video: videoConstraint };
    }

    // Quaggaデバッグ描画（完全ガード）
    function attachQuaggaProcessed(Q, getCanvasSize) {
      if (!Q || typeof Q.onProcessed !== "function") return;
      const ctx = overlay.getContext("2d", { willReadFrequently: true });
      Q.onProcessed((result) => {
        if (!ctx) return;
        const { w, h } = getCanvasSize();
        if (overlay.width !== w) overlay.width = w;
        if (overlay.height !== h) overlay.height = h;
        ctx.clearRect(0, 0, w, h);

        if (!result) return;

        // boxes
        if (Array.isArray(result.boxes)) {
          ctx.strokeStyle = "rgba(0,255,0,0.7)";
          ctx.lineWidth = 2;
          result.boxes.forEach((box) => {
            if (!Array.isArray(box)) return;
            ctx.beginPath();
            box.forEach((p, i) => {
              if (!p || typeof p.x !== "number" || typeof p.y !== "number") return;
              if (i === 0) ctx.moveTo(p.x, p.y); else ctx.lineTo(p.x, p.y);
            });
            ctx.closePath();
            ctx.stroke();
          });
        }

        // line
        if (result.line && result.line[0] && result.line[1]) {
          const a = result.line[0], b = result.line[1];
          if (a && b && typeof a.x === "number" && typeof a.y === "number" && typeof b.x === "number" && typeof b.y === "number") {
            ctx.strokeStyle = "rgba(255,0,0,0.85)";
            ctx.lineWidth = 3;
            ctx.beginPath();
            ctx.moveTo(a.x, a.y);
            ctx.lineTo(b.x, b.y);
            ctx.stroke();
          }
        }
      });
    }

    // アダプタ
    const Adapters = {
      quagga: {
        Q: window.__Quagga_v0121__,
        _detectedHandler: null,
        _started: false,
        async init(videoEl, constraints) {
          t0 = performance.now();

          // 1) 先にストリーム確保（プレビュー用）
          stream = await navigator.mediaDevices.getUserMedia(constraints);
          videoEl.srcObject = stream;
          await videoEl.play();

          // overlayキャンバスのサイズ同期関数
          const getCanvasSize = () => {
            const rect = videoEl.getBoundingClientRect();
            // 実描画スケールに近い整数に
            const w = Math.max(1, Math.round(rect.width));
            const h = Math.max(1, Math.round(rect.height));
            return { w, h };
          };

          // 2) Quagga 初期化
          await new Promise((res, rej) => {
            try {
              this.Q.init({
                inputStream: {
                  name: "Live",
                  type: "LiveStream",
                  target: videoEl,              // videoに重ねる
                  constraints: constraints.video,
                  area: {                       // 読み取り領域は全画面（必要なら絞って高速化可）
                    top: "0%", right: "0%", left: "0%", bottom: "0%"
                  }
                },
                locator: { patchSize: "medium", halfSample: true },
                decoder: { readers: ["ean_reader"] }, // EAN-13 のみに絞る
                locate: true,
                numOfWorkers: (navigator.hardwareConcurrency ? Math.min(4, Math.max(1, navigator.hardwareConcurrency - 1)) : 2)
              }, (err) => err ? rej(err) : res());
            } catch (e) { rej(e); }
          });

          // 3) onProcessed を安全に設定
          attachQuaggaProcessed(this.Q, getCanvasSize);

          t1 = performance.now();
        },
        async startScan(onResult) {
          // start前に内部状態をクリーンに
          try { this.Q.stop(); } catch {}
          if (this._detectedHandler && typeof this.Q.offDetected === "function") {
            try { this.Q.offDetected(this._detectedHandler); } catch {}
          }

          s0 = performance.now();

          this._detectedHandler = (res) => {
            if (!res || !res.codeResult || !res.codeResult.code) return;
            s1 = performance.now();
            onResult({ text: res.codeResult.code, format: res.codeResult.format });
            try { this.Q.stop(); } catch {}
            this._started = false;
          };

          if (typeof this.Q.onDetected === "function") {
            this.Q.onDetected(this._detectedHandler);
          }

          // 重要: quagga 0.12系の内部で undefined data を参照するケースの緩和
          // - start 直後に onProcessed が走り、内部 ImageWrapper.data が未準備だと落ちることがある
          // - 1フレーム遅延させて start
          await new Promise(r => setTimeout(r, 0));

          this.Q.start();
          this._started = true;
        },
        async stopScan() {
          try { this.Q.stop(); } catch {}
          this._started = false;
        },
        async teardown() {
          try { this.Q.stop(); } catch {}
          if (typeof this.Q.offProcessed === "function") {
            try { this.Q.offProcessed(); } catch {}
          }
          if (typeof this.Q.offDetected === "function" && this._detectedHandler) {
            try { this.Q.offDetected(this._detectedHandler); } catch {}
          }
          this._detectedHandler = null;

          if (stream) {
            stream.getTracks().forEach(t => t.stop());
            stream = null;
          }
          video.srcObject = null;
          // overlay クリア
          const ctx = overlay.getContext("2d");
          if (ctx) ctx.clearRect(0, 0, overlay.width, overlay.height);
        }
      },

      quagga2: {
        Q2: window.__Quagga2_v172__,
        _detectedHandler: null,
        _started: false,
        async init(videoEl, constraints) {
          t0 = performance.now();

          stream = await navigator.mediaDevices.getUserMedia(constraints);
          videoEl.srcObject = stream;
          await videoEl.play();

          const getCanvasSize = () => {
            const rect = videoEl.getBoundingClientRect();
            return { w: Math.max(1, Math.round(rect.width)), h: Math.max(1, Math.round(rect.height)) };
          };

          await new Promise((res, rej) => {
            try {
              this.Q2.init({
                inputStream: {
                  name: "Live",
                  type: "LiveStream",
                  target: videoEl,
                  constraints: constraints.video,
                  area: { top: "0%", right: "0%", left: "0%", bottom: "0%" }
                },
                locator: { patchSize: "medium", halfSample: true },
                decoder: { readers: ["ean_reader"] },
                locate: true,
                numOfWorkers: (navigator.hardwareConcurrency ? Math.min(4, Math.max(1, navigator.hardwareConcurrency - 1)) : 2)
              }, (err) => err ? rej(err) : res());
            } catch (e) { rej(e); }
          });

          attachQuaggaProcessed(this.Q2, getCanvasSize);

          t1 = performance.now();
        },
        async startScan(onResult) {
          try { this.Q2.stop(); } catch {}
          if (this._detectedHandler && typeof this.Q2.offDetected === "function") {
            try { this.Q2.offDetected(this._detectedHandler); } catch {}
          }

          s0 = performance.now();

          this._detectedHandler = (res) => {
            if (!res || !res.codeResult || !res.codeResult.code) return;
            s1 = performance.now();
            onResult({ text: res.codeResult.code, format: res.codeResult.format });
            try { this.Q2.stop(); } catch {}
            this._started = false;
          };

          if (typeof this.Q2.onDetected === "function") {
            this.Q2.onDetected(this._detectedHandler);
          }

          await new Promise(r => setTimeout(r, 0));
          this.Q2.start();
          this._started = true;
        },
        async stopScan() {
          try { this.Q2.stop(); } catch {}
          this._started = false;
        },
        async teardown() {
          try { this.Q2.stop(); } catch {}
          if (typeof this.Q2.offProcessed === "function") {
            try { this.Q2.offProcessed(); } catch {}
          }
          if (typeof this.Q2.offDetected === "function" && this._detectedHandler) {
            try { this.Q2.offDetected(this._detectedHandler); } catch {}
          }
          this._detectedHandler = null;

          if (stream) {
            stream.getTracks().forEach(t => t.stop());
            stream = null;
          }
          video.srcObject = null;
          const ctx = overlay.getContext("2d");
          if (ctx) ctx.clearRect(0, 0, overlay.width, overlay.height);
        }
      },

      zxing: {
        _reader: null,
        _running: false,
        async init(videoEl, constraints) {
          t0 = performance.now();
          const tuned = JSON.parse(JSON.stringify(constraints));
          tuned.video = tuned.video || {};
          if (typeof tuned.video === "object") {
            if (!('width' in tuned.video)) tuned.video.width = { ideal: 1280 };
            if (!('height' in tuned.video)) tuned.video.height = { ideal: 720 };
            if (!('frameRate' in tuned.video)) tuned.video.frameRate = { ideal: 30 };
          }
          stream = await navigator.mediaDevices.getUserMedia(tuned);
          videoEl.srcObject = stream;
          await videoEl.play();

          const hints = new Map();
          hints.set(ZXing.DecodeHintType.POSSIBLE_FORMATS, [ZXing.BarcodeFormat.EAN_13]);
          // hints.set(ZXing.DecodeHintType.TRY_HARDER, true); // 難読時のみ

          this._reader = new ZXing.BrowserMultiFormatReader(hints);
          t1 = performance.now();
        },
        async startScan(onResult) {
          if (this._running) return;
          this._running = true;
          s0 = performance.now();
          this._reader.decodeFromVideoElementContinuously(video, (result, err) => {
            if (result) {
              const txt = result.getText();
              if (!s1) s1 = performance.now();
              onResult({ text: txt, format: result.getBarcodeFormat() });
              this._reader.reset();
              this._running = false;
            }
          });
        },
        async stopScan() {
          if (this._reader) this._reader.reset();
          this._running = false;
        },
        async teardown() {
          await this.stopScan();
          if (stream) { stream.getTracks().forEach(t => t.stop()); stream = null; }
          video.srcObject = null;
          this._reader = null;
          const ctx = overlay.getContext("2d");
          if (ctx) ctx.clearRect(0, 0, overlay.width, overlay.height);
        }
      }
    };

    async function ensureAdapter() {
      const key = selLib.value;
      return Adapters[key];
    }

    function syncOverlaySizeToVideo() {
      const rect = video.getBoundingClientRect();
      const w = Math.max(1, Math.round(rect.width));
      const h = Math.max(1, Math.round(rect.height));
      if (overlay.width !== w) overlay.width = w;
      if (overlay.height !== h) overlay.height = h;
    }

    function printTimes() {
      if (t0 && t1) log(`起動時間: ${(t1 - t0).toFixed(1)} ms`);
      if (s0 && s1) log(`認識開始→検出: ${(s1 - s0).toFixed(1)} ms`);
    }

    // イベント
    $("#btnInit").onclick = async () => {
      try {
        if (adapter) await adapter.teardown();

        // overlay サイズを一旦クリア
        overlay.width = 1; overlay.height = 1;

        adapter = await ensureAdapter();
        const constraints = getConstraints();
        t0 = 0; t1 = 0; s0 = 0; s1 = 0;
        await adapter.init(video, constraints);

        // video が可視サイズ決定後に overlay を同期
        syncOverlaySizeToVideo();
        // リサイズにも追従
        window.addEventListener("resize", syncOverlaySizeToVideo, { passive: true });

        const devLabel = selDev.selectedOptions[0]?.textContent || "";
        const preset = selPreset.value;
        ok(`[${selLib.value}] カメラ起動完了  device="${devLabel}" preset=${preset}`);
        printTimes();

        recordResult({
          lib: selLib.value,
          deviceLabel: devLabel,
          preset,
          init_ms: (t1 && t0) ? (t1 - t0).toFixed(1) : "",
          detect_ms: "",
          text: "",
          format: ""
        });
      } catch (e) {
        err("init error:", e);
      }
    };

    $("#btnStart").onclick = async () => {
      try {
        if (!adapter) { warn("先に「カメラ起動」を実行してください。"); return; }
        s0 = 0; s1 = 0;
        const devLabel = selDev.selectedOptions[0]?.textContent || "";
        const preset = selPreset.value;
        await adapter.startScan((res) => {
          ok(`検出: ${res.text} (${res.format})`);
          printTimes();
          recordResult({
            lib: selLib.value,
            deviceLabel: devLabel,
            preset,
            init_ms: (t1 && t0) ? (t1 - t0).toFixed(1) : "",
            detect_ms: (s1 && s0) ? (s1 - s0).toFixed(1) : "",
            text: res.text,
            format: res.format
          });
        });
      } catch (e) {
        err("start error:", e);
      }
    };

    $("#btnStop").onclick = async () => {
      try {
        await adapter?.stopScan();
        ok("停止しました。");
      } catch (e) {
        err("stop error:", e);
      }
    };

    $("#btnTeardown").onclick = async () => {
      try {
        await adapter?.teardown();
        adapter = null;
        ok("解放しました。");
      } catch (e) {
        err("teardown error:", e);
      }
    };

    $("#btnExport").onclick = exportCSV;

    // 初期セットアップ: カメラ一覧
    (async () => {
      try {
        const tmp = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
        tmp.getTracks().forEach(t => t.stop());
      } catch (e) {
        // 権限が無くても続行
      }
      try {
        await listDevices();
        ok("カメラ一覧を取得しました。");
      } catch (e) {
        err("カメラ一覧の取得に失敗しました。", e);
      }
    })();

    // 備考:
    // - 以前の「Cannot read properties of undefined (reading 'data')」は、特に quagga 0.12 系で
    //   start 直後に onProcessed が走り、内部の画像バッファが未準備なフレームを触ると発生しがちです。
    //   対策として start 前に setTimeout(...,0) で 1 tick 遅延、描画は完全ガード、overlay は明示の canvas に固定。
    // - また inputStream.target を video に固定し、constraints を一致させることで内部の LiveStream 構成不整合を回避しています。
  </script>
</body>
</html>
